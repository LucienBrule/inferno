# Inferno Codebase Deep Analysis and Linting Strategy

---

## Repository Structure and Major Components

The Inferno project is organized as a **monorepo** with several Python packages, each serving a specific role in the framework:

- **inferno-core**: The core library containing fundamental data structures and logic. This includes the data loading mechanisms (e.g. YAML manifest loader), Pydantic domain models (e.g. topology definitions), and validation rules for domain policies (cabling, power, naming conventions, etc.). This is the heart of the domain logic and data representation.
- **inferno-tools**: A collection of domain-specific tools and calculations. For example, modules under `inferno_tools/cooling` handle cooling capacity and DX (direct expansion) constants, while `inferno_tools/cabling` provides functions to estimate, calculate, and validate cabling requirements. These tools implement business logic and algorithms, and are meant to be called by orchestrators or the CLI, rather than doing any direct file I/O.
- **inferno-cli**: The command-line interface package. It provides user-facing commands (in `inferno_cli/tools/*`) that parse arguments and invoke the appropriate functions in inferno-core or inferno-tools. Important: the CLI is intended to contain no significant business logic – it should delegate to core logic and just handle user interaction and output formatting.
- **doctrine (manifests & schemas)**: A directory (likely at the repository root) containing YAML files and schema definitions for various domains – e.g. `site.yaml`, `network.yaml`, `naming.yaml`, `power.yaml`. These files define expected structures and cross-file references for data (almost like a source-of-truth or contracts for the data). The core package probably uses these for validation and ensuring consistency across different configuration files.
- **.junie directory (tasks & scripts)**: A special directory present in the repo that appears to track internal project management context. For instance, `.junie/scripts/epic-audit-2.sh` and other notes were mentioned. This likely contains automation scripts and planning notes for the current development “epic.” It may include to-do lists or open tasks being handled by the team or an AI agent named “Junie.” In our context, the `.junie` notes describe the InfernoLint plan (SOPUC 0) – essentially the blueprint for introducing a custom linter and improving architecture compliance.

Each package has a clear role under a **domain-driven design** approach. The separation ensures that, for example, models and validation rules reside in inferno-core (the domain layer), domain computations in inferno-tools (services layer), and user interaction in inferno-cli (interface layer). This layered structure supports a clean architecture, making the system easier to maintain and extend.

---

## Architectural Constraints and Best Practices (DRY, Clean, DDD)

The team has established several architectural guidelines to uphold DRY, Clean Architecture, and Domain-Driven Design (DDD) principles:

- **Don’t Repeat Yourself (DRY):** Avoid duplicating logic or scattering similar functionality in multiple places. A single authoritative implementation should exist for each piece of functionality. For example, YAML parsing of manifests should happen in one place (a generic loader utility) rather than ad-hoc throughout the code. This reduces inconsistency and simplifies updates.
- **Clean Architecture & Separation of Concerns:** Different layers of the application have distinct responsibilities. Business logic is separated from input/output code. The CLI should not contain core logic; it should only coordinate user input and output, delegating to the inferno-core/inferno-tools functions for actual processing. Similarly, data access (like reading files) should be handled by designated utility functions rather than scattered in the domain logic. This separation makes the system easier to test and evolve.
- **Domain-Driven Design (DDD):** The system is structured around domain concepts. Domain models (using Pydantic `BaseModel` classes) represent core entities like a network topology, site configuration, etc. These models should reside in a dedicated area (e.g. `inferno_core/models`) and be the primary way data is passed around, rather than raw dictionaries. By using strong typing and schema, the code more accurately reflects domain concepts and invariants. Also, domain-specific computations (cooling, cabling, power) are encapsulated in dedicated modules under inferno-tools, which align with bounded contexts in the domain.
- **Single Source of Truth for Data and Config:** Manifest files (YAML) and schema definitions (in `doctrine/*`) define the expected structure of input data. The loader in inferno-core should be the single gateway for reading these files into models. This ensures that any change in data format or schema is handled in one place, and all consumers get consistent behavior. It also means any validation or defaulting logic in loading is uniformly applied (preventing subtle bugs where one part of the code interprets data differently than another).
- **Explicitness and Type Safety:** Using Pydantic models and typed functions (e.g., `load_yaml_typed[T]`) makes data transformations explicit and type-checked. Functions should declare their inputs/outputs in terms of these models or other clear types (avoiding ambiguous types like `Dict[str, Any]` in public interfaces). This improves clarity for developers and catches errors early (an embodiment of the “make illegal states unrepresentable” idea in DDD).

Adhering to these principles not only improves code quality but also makes the codebase easier for an automated assistant (and new developers) to understand. The upcoming custom linter **InfernoLint** is designed to enforce these rules mechanically, catching violations of the architecture guidelines early in development.

---

## Proposed Lint Rules (INF100–INF109)

To codify the above constraints, a suite of **InfernoLint rules (INFxxx)** has been outlined. These AST-based rules target specific patterns in the code. Below is a summary of each rule and its rationale:

- **INF100 – No ad-hoc YAML I/O outside the loader**: Disallow direct use of `yaml.safe_load`, manual file opens, or hard-coded file paths for manifest data in any module except the centralized loader utility. All YAML configuration data (manifests) should be loaded via a unified function (e.g. `inferno_core.data.loader.load_yaml_typed`). This ensures consistent parsing and schema validation. For example, calling `yaml.safe_load(open('config.yaml'))` in a random module would violate INF100 (that logic must move to the loader).
- **INF101 – No `Dict[str, Any]` in public APIs**: Functions or methods that are part of the public interface should not return untyped dictionaries. Instead, they should return Pydantic models or well-defined TypedDicts/dataclasses. This rule flags any function signature that returns a generic dict (especially in something like a `load_*` function). The goal is to enforce explicit domain types – for instance, `load_site_config()` should return a `SiteConfigModel` instead of `Dict[str, Any]`. This improves type safety and maintainability.
- **INF102 – Models defined only in `inferno_core.models`**: Any class inheriting from Pydantic’s `BaseModel` must reside in a module path that includes `/models/`. In other words, all domain models belong in the `inferno_core.models` package. If a model class is found elsewhere (say in a tool or CLI module), the linter will flag it. This keeps domain definitions centralized, avoiding duplication or hidden model definitions scattered around.
- **INF103 – CLI commands must remain pure orchestrators**: The CLI layer should not perform file I/O, YAML parsing, or complex computations. It should only parse CLI arguments, call appropriate functions in inferno-core or inferno-tools, and format the results for output. This rule will flag forbidden operations in `inferno_cli/tools/*` such as opening files, calling `yaml.load`, or implementing heavy logic. The rationale is to keep the CLI thin and maintain a clean separation between presentation and logic.
- **INF104 – Topology loads must be strongly typed**: When loading topology data (or similar large config structures), the code must specify a Pydantic model view. For example, instead of doing `load_yaml('topology.yaml')` into a raw dict, one should call something like `load_yaml_typed[TopologyFull]('topology.yaml')` or use a dedicated loader function (e.g. `load_topology_full()`). This rule likely ensures that any call to a generic loader function includes a type parameter or uses a specialized function, preventing untyped usage of important data. It guarantees that the two different “views” of topology (full vs. graph summary) are explicitly chosen and handled.
- **INF105 – No manual resource path construction**: Code should not manipulate `__file__` paths to find resource files. Patterns like `Path(__file__).parent / "data" / "file.yaml"` or using `os.path.dirname(__file__)` are discouraged. Instead, a resource loader or package data mechanism should be used. This prevents mistakes in path handling and makes it easier to relocate resources (for example, if packaged, using `importlib.resources`). INF105 will catch uses of `Path(__file__)` and similar in the code and prompt using the loader APIs or configuration to locate files.
- **INF106 – Graph rendering confined to a single module**: Only the dedicated graph visualization module (e.g. an `inferno_graph` utility or a specific part of inferno-tools) should import graph libraries like `networkx` or `graphviz`. Other modules needing graph operations must go through this module’s interface. This rule will flag any import of `networkx`, `graphviz`, or similar graph library outside the allowed module. The intent is to avoid multiple implementations of graph traversal and ensure consistent graph rendering logic (perhaps all graph drawings funnel through `inferno_graph.render(...)`).
- **INF107 – Avoid brittle tests (prefer structured assertions)**: Tests should not rely on large regex matches or full-string equality on generated outputs when a structured approach is possible. For example, if a function outputs a YAML or JSON, tests should parse that output and assert on specific keys/values rather than comparing giant multiline strings or using regex to find text. The linter can flag usage of suspicious patterns like `re.match` on a multi-line string or comparisons of entire file dumps. This rule pushes developers to write more resilient tests that won’t break with minor formatting changes.
- **INF108 – Deprecated functions must issue warnings**: If a function is marked as deprecated (e.g. via a `@deprecated` decorator or in documentation), it must emit a `DeprecationWarning` when used. This ensures that users of the library get a runtime warning guiding them to newer APIs. The rule will likely ensure any `@deprecated` decorator usage is accompanied by a `warnings.warn(..., DeprecationWarning)` call inside the function. It may also flag the absence of test coverage for that warning (to ensure the deprecation mechanism is working).
- **INF109 – Constants and “magic numbers” hygiene**: Domain-specific constants (especially in modules like cooling and cabling) should be defined as named constants in `UPPER_SNAKE_CASE` at module level, not inlined in code. E.g., if “42” or “3.14” has significance (max temperature, conversion factor, etc.), it should be something like `MAX_TEMP_C = 42` defined at top of the module. The linter can detect literal numbers or strings that seem to recur or are used where a constant could be expected, and flag them. This enforces clearer code and easier tuning of domain parameters, adhering to clean code practices.

Each rule above is designed to address a specific anti-pattern observed in the codebase. Together, they form a comprehensive InfernoLint suite that encodes the team’s architectural best practices.

---

## Current Hotspots and Rule Violation Examples

As part of this deep research, we identify areas in the current code that would trigger the new lint rules. Addressing these will likely form a big part of the upcoming refactoring tasks:

- **Ad-hoc YAML Loading (INF100):** There are instances of YAML files being loaded in a scattered way. For example, some validation or tool modules use `yaml.safe_load` on their own data files, or use `open(...).read()` to pull in a YAML fragment. These occurrences need to be refactored to use the central `load_yaml_typed` function. One likely example is in cabling or naming validation code, where a YAML of expected patterns might be read with `open(path)`. These should instead call the loader utility (with an appropriate model if available).
- **Untyped Dict Returns (INF101):** Certain loader or parser functions currently return raw dict objects. A suspect area is any function named `load_*` or `parse_*` in inferno-core that doesn’t explicitly declare a model return type. For instance, if `inferno_core.data.loader` has a generic `load_yaml` that returns `Dict[str, Any]`, that’s a prime target for replacement with a typed model. Similarly, if any function in inferno-tools is returning a dict of results (instead of a defined model or dataclass), that will need attention. These functions should be rewritten to return Pydantic models (or at least TypedDicts) representing the data.
- **Pydantic Models Outside `models` (INF102):** We need to scan for any class inheriting `BaseModel` that lives outside the `inferno_core/models` directory. If, for example, a test or a tool defines a quick Pydantic model for internal use, it technically violates this rule. One area to check is the test fixtures or any dynamic model creation. If found and they represent real domain entities, they should be moved into the models module. If they’re purely for testing, we might mark them with `# noqa: INF102` or otherwise justify them. Early review suggests most domain models (topologies, device definitions, etc.) are indeed under `inferno_core.models`, but this rule will enforce that strictly.
- **CLI Doing Too Much (INF103):** A review of `inferno_cli/tools` will reveal any CLI commands that perform forbidden actions. For example, if a CLI command opens a file (to read input or write output) or parses YAML/JSON directly, that’s a violation. The CLI should call a function in inferno-core or tools which returns the needed data, then the CLI might just print it or save it. We suspect some existing commands might read configuration files directly for convenience. Those will need refactoring. As a concrete example, a command like `inferno site-validate` might currently open a `site.yaml` and do inline validation – under the new approach, that logic should move to a function like `inferno_core.validation.validate_site()` and the CLI just calls it with the file path.
- **Topology Loading without Type (INF104):** The code dealing with network topologies (likely under `inferno_core.models.topology` or `inferno_core.validation.topology`) might currently load a YAML and then manually create two different views (a full data model vs. a graph representation). If we find calls such as `data = load_yaml(path)` followed by logic to interpret that data, that indicates an untyped load. The plan is to introduce `TopologyFull` and `TopologyGraphView` models, so that one can load directly into the desired form. Until those exist, such code is essentially a violation of the envisioned INF104. Refactoring will involve defining those models and altering the load calls to use them. We might also provide convenience functions like `load_topology_full(path)` and `load_topology_graph(path)` to wrap the generic loader with the right model type.
- **Resource Path Construction (INF105):** Searching the codebase reveals some instances of file path math using `Path(__file__)` or `os.path`. These are typically in scenarios where a module needs to access a resource file shipped with the code (for example, a YAML template or a default config under the doctrine folder). For instance, a validation module might do something like: `BASE_DIR = Path(__file__).parent; schema_path = BASE_DIR / "doctrine" / "site.yaml"`. According to INF105, these should be replaced with a call to a loader or a resource-fetching utility (e.g., using `importlib.resources` or a known data directory reference). The new linter rule will catch these lines (as illustrated by it flagging any use of `Path(__file__)` or `__file__` in path joins). Each such occurrence is an immediate fix candidate. Instead of computing paths manually, the code could ask the loader for the path or data (for example, `loader.get_path("site.yaml")` or `load_yaml_typed(SiteModel, "site.yaml")` once a standard location is known).
- **Graph Library Usage (INF106):** If graph algorithms or visualization are used, they should be centralized. We need to locate any `import networkx` or `import graphviz` in the code. Suppose `inferno_core.validation.topology` is building a graph of the network to verify connectivity – it might be directly using `networkx` today. Under INF106, that should be refactored: perhaps an `inferno_graph` module (or a submodule in tools) will provide an API like `build_graph(topology_model)` or `render_topology_graph(topology_model)`. Then other code would call that instead of using `networkx` directly. The immediate task is identifying those direct imports. They will need to be removed or isolated behind a facade. This may also entail moving some of that logic out of core modules into the new graph utility module.
- **Brittle Test Patterns (INF107):** A scan of the test suite would look for things like `assert "some substring" in output` or regex matches against large outputs. For example, if there’s a test that runs a CLI command and then does `assert re.search("Success", result.stdout)`, it’s somewhat brittle (format changes could break it). Instead, if the CLI returns a structured result or writes a JSON, tests should load that and verify specific fields. Another example is tests that compare entire files: e.g., reading a generated YAML file as text and comparing to an expected text blob. Those can fail on trivial differences like spacing. A better approach is to parse both YAMLs and compare data structures. We will need to rewrite such tests gradually. In the interim, we might tag them with `@pytest.mark.legacy` to differentiate them. An immediate find might be tests under `inferno_core/tests` that validate BOM (Bill of Materials) output or cross-file references by matching strings – these should be targeted for improvement.
- **Deprecation Warnings (INF108):** We should identify any functions in the code marked as deprecated. For instance, if `inferno_core.data.loader.load_yaml` is being replaced by `load_yaml_typed`, the former might be kept for backward compatibility but considered deprecated. If so, calling it should emit a warning. We need to implement a standard `@deprecated` decorator (if not already present) that wraps the function and issues a `warnings.warn(..., DeprecationWarning)` on use. Then apply this decorator to all legacy APIs we intend to phase out (ensuring that tests expect the warning). If currently no warnings are emitted, it’s a gap to fix. This rule is more about ensuring we don’t silently maintain old functions; instead we loudly warn and push users towards the new approach.
- **Magic Numbers and Constants (INF109):** The domain calculation modules (cooling, power, etc.) are likely to have some numeric literals in formulas. For example, cooling might have something like `cooling_capacity_kw * 3.412` (just as an illustration) hard-coded. INF109 would prefer this be `BTU_TO_KW = 3.412` at the top of the module and then use `cooling_capacity_kw * BTU_TO_KW`. We should audit `inferno_tools.cooling` and `inferno_tools.cabling` for such literals. Another area to check is any threshold values or default limits in validation logic – those too should be named constants. By addressing these, we not only make the code self-documenting, but also easier to adjust (tuning a constant in one place updates all uses). The immediate task is to catalog these magic values and define meaningful constant names for them. The linter will help by flagging occurrences of numeric literals that aren’t obviously just simple increments or indices.

Overall, most of these violations are not catastrophic bugs, but rather technical debt and inconsistencies that the new lint rules will surface. Tackling them will greatly improve code consistency and enforce the intended architecture.

---

## Task Breakdown and Next Steps

Based on the analysis and the planned lint introduction, here is a breakdown of tasks to be undertaken. These tasks will ensure the codebase adheres to the new standards and the linter can be rolled out smoothly:

### A. InfernoLint Implementation

1.  **Scaffold the inferno-lint package:** Create a new package under `packages/inferno-lint`. Implement the basic structure: a `BaseRule` abstract class (for AST NodeVisitor rules), individual rule classes for INF100–INF109, and a flake8 plugin integration. For example, set up `inferno_lint/plugin.py` with a `Plugin` class that collects all rule classes and yields their violations. Ensure this plugin is registered in `pyproject.toml` under flake8 extensions (e.g., `flake8.extension = INF = inferno_lint.plugin:Plugin`).
2.  **Implement lint rules INF100–INF109:** For each rule:
    - Write the AST visitor logic to detect the pattern. (Many can be adapted from the GlyphSieve examples the team has from earlier.) For instance, INF100 will flag calls to `yaml.safe_load` or `open()` on `.yaml` files outside the loader module. INF105 will catch `Path(__file__)` usage. Similarly, INF101 can inspect function return type annotations for `Dict[str, Any]`. Implement all rules, each producing a clear message with the code (e.g. “INF101: function returns untyped dict, use a model”).
    - Unit tests for each rule: Under `inferno-core/tests/lint/` (or a new tests directory for inferno-lint), create small dummy Python snippets and assert that the linter flags or does not flag appropriately. For example, a test file with a fake `load_something()` returning `Dict[str, Any]` should yield an INF101 violation.
3.  **Integrate with CI (initially non-blocking):** Add the new linter to the CI pipeline. Initially run it in “warning” mode (e.g., `flake8 --select=INF --exit-zero`) so that it reports issues but does not fail the build. This will produce a baseline list of warnings for developers to address. Over time, as fixes are made, rules will be configured to be enforced (non-zero exit).

### B. Code Refactoring for Compliance

4.  **Centralize YAML Loading:** Finalize and promote the `inferno_core.data.loader.load_yaml_typed` utility. This function should take a path and a Pydantic model type `T`, then open and parse the YAML into an instance of `T`. If such a function was partially implemented, complete it. Also, implement safe file handling (use `Path` or `importlib.resources` to locate built-in files). Mark any old functions (like a generic `load_yaml` or `_read_yaml`) as deprecated.
5.  **Replace direct YAML reads with loader calls:** Search the codebase for any direct uses of `yaml.safe_load` or file opens for `.yaml` files. Refactor each occurrence:
    - If parsing input manifests, call `load_yaml_typed[AppropriateModel](path)` instead (you may need to create new model classes for some, e.g., `SiteConfigModel`, if they don’t exist).
    - If in tests, use the loader or at least centralize how test data is loaded (perhaps via a test utility function).
    - Remove or deprecate any redundant YAML parsing logic scattered around.
6.  **Introduce Topology view models:** Define the two planned topology models in `inferno_core.models`:
    - `TopologyFull` – represents the full topology data structure (all details from the YAML).
    - `TopologyGraphView` (or `TopologyCompact`) – a pared-down representation suitable for graph algorithms (e.g., nodes and edges).
    These models can share some base or be constructed from each other. Add corresponding loader functions `load_topology_full(path)` and `load_topology_graph(path)` in the data loader module, which simply call `load_yaml_typed[TopologyFull]` or `[TopologyGraphView]` under the hood.
7.  **Refactor topology-related code to use new models:** Go through any code that currently handles topology data:
    - If a function expects a dict of topology info, change it to expect a `TopologyFull` model. Adjust internal logic accordingly (access model fields instead of dict keys).
    - If a function was constructing a `networkx` graph from a dict, consider moving that logic into a method of `TopologyGraphView` or a function in a new `inferno_core.graph` module (see below).
    - Update validation routines to leverage the rich model (for example, use Pydantic validation features rather than re-parsing raw dicts).
8.  **Enforce CLI purity:** Audit each command in `inferno_cli/tools/*.py`. For each:
    - Ensure it accepts input in simple forms (e.g., file paths or IDs) and calls a function in inferno-tools or inferno-core to do the work. If the CLI command is doing something like `with open(file) as f: data = yaml.safe_load(f)`, move that logic into, say, `inferno_core.data.loader` or a new function in inferno-core, and have the CLI simply call that and handle the result.
    - Remove any business logic from CLI (e.g., calculations, complex conditionals that belong in core). The CLI should be mostly argument parsing and calling into core functions.
    - As needed, create new functions in inferno-tools/core to take over the logic. For example, if `inferno_cli/tools/generate_cabling.py` was reading a template and calculating lengths, put that in `inferno_tools.cabling.generate_cabling_plan()` and call it from the CLI.
9.  **Isolate graph library usage:** Create a dedicated place for graph operations, if not already present. This could be:
    - A new module `inferno_core.graph` or `inferno_tools.graph` that wraps `networkx`/`graphviz` usage. It might contain functions like `topology_to_nx(topology: TopologyFull) -> networkx.Graph` or `render_topology_graph(graph) -> image`.
    - Move any direct imports of `networkx`/`graphviz` into this module. Other modules requiring graph functionality should import from here instead. For instance, `inferno_core.validation.topology` might call `graph = inferno_graph.topology_to_nx(topology_model)` rather than using `networkx` itself.
    - Verify that after this, only the graph module has those third-party imports (the linter INF106 will help catch stragglers).
10. **Define and use named constants:** Go through modules like cooling and cabling:
    - Identify numeric literals and key strings. For each, define a constant at module top. E.g., replace `if temp > 35:` with `MAX_TEMP_C = 35` at top and use `if temp > MAX_TEMP_C:` in code. Give the constants meaningful names (`COOLING_FACTOR`, `CABLE_LOSS_FACTOR`, etc., as appropriate).
    - Ensure all constants follow the `SCREAMING_SNAKE_CASE` convention. If some configuration constants exist but are lowercase or not obviously constant, rename them (this might involve minor changes in references across the code).
    - Double-check that tests or documentation are updated if they referenced the old literal values.
11. **Implement deprecation warnings:** Develop a simple decorator or pattern for deprecated functions:
    - Possibly something like:
      ```python
      import warnings
      def deprecated(func):
          def wrapper(*args, **kwargs):
              warnings.warn(f"{func.__name__} is deprecated and will be removed in a future release", DeprecationWarning)
              return func(*args, **kwargs)
          return wrapper
      ```
    - Apply this to old functions we plan to remove later.
    - Mark functions like the old YAML loaders with `@deprecated`. Add unit tests that call those functions and assert that a `DeprecationWarning` is raised (using `pytest`’s warning capture).
    - Ensure the linter INF108 will catch if someone forgets to add the warning in a deprecated function.

### C. Testing and Validation

12. **Revise brittle tests:** Identify tests that are prone to false negatives/positives due to overly broad assertions. Refactor them to be more precise:
    - When comparing output files, parse them (e.g., if output is YAML or JSON, load it and compare data structures or key subsets).
    - Use specific assertions for important fields rather than full string matches. For example, if testing an error message, assert that the error code or keyword is present, not the entire phrasing.
    - Where refactoring tests fully is too time-consuming (especially if a large output is involved), mark those tests with `@pytest.mark.legacy` or similar, so they can be skipped or isolated during initial rollout. This will allow incremental improvement without breaking CI.
    - Add new tests for any new behavior introduced (e.g., tests for the new loader functions and topology models, tests for graph module functions, etc.).
13. **Documentation of rules and practices:** Create or update documentation (e.g. `docs/architecture/linting.md`):
    - For each INF rule, write a short explanation (the “why” behind it) and show a small code example of a violation and a compliant solution. This will help developers and contributors understand the intent and how to fix issues.
    - Document the proper ways to perform common tasks (e.g. “How to load a manifest YAML into a model”, “How to add a new constant for a calculation”) so that new code adheres to these standards from the start.
    - Update README or developer guide sections to mention the new pre-commit checks and lint rules.

### D. Rollout and Enforcement

14. **Staged Lint Enforcement:** Once the linter is implemented and reporting issues:
    - Triage the INF warnings from the first run. Prioritize fixes for the most critical or easiest-to-fix violations (perhaps INF100, INF105, INF103 first, which have straightforward fixes).
    - Fix issues in the codebase in batches (it may be useful to create a checklist of all occurrences of each rule violation and address them). Some fixes can be automated or scripted (for example, replacing `yaml.safe_load` calls with the loader function). Others require design changes (like introducing new models for INF104).
    - During the initial rollout, keep the lint checks non-blocking but ensure the team is aware of them (maybe integrate it into pull request checks with warnings). When a rule’s violations reach zero, turn that rule on as an error (enforced). According to the plan, INF100, INF102, INF103, INF105 might be among the first to be fully enforced once cleaned up.
    - Communicate these changes in team channels so that everyone adjusts their workflow (e.g., “CLI code should now follow these patterns…”, “Use the new loader for any YAML file”, etc.).
15. **Pre-commit and CI updates:** Integrate the lint and test improvements into the developer workflow:
    - Add a pre-commit hook configuration that runs formatting (if any), ruff (for general linting/format), and flake8 with inferno-lint for the INF rules. This will catch issues even before pushing to CI.
    - Ensure the CI pipeline runs the full test suite and linter. Eventually, when all planned rules are enforced, CI should fail on any new INF rule violation (protecting the architecture going forward).
    - Monitor CI for any unexpected breakages due to these changes, especially in the early phases (some tests might initially fail if they were relying on old behaviors; update them accordingly).

By executing these tasks in a staged manner (as outlined in the internal plan’s day-by-day sequence), the team will incrementally improve the codebase. The end goal is that after this effort:

- All YAML and other resource loading is centralized and type-checked.
- Public interfaces and cross-module interactions are clean and well-defined via models.
- The CLI is lean and maintainable, and new features can be added without risking architectural drift.
- Tests are more reliable, focusing on behavior rather than exact string output, reducing maintenance cost when internals change.
- The custom InfernoLint ensures these standards remain in place, acting as an automated guardian of architecture. Over time, developers will internalize these guidelines, and the linter will catch any slips.

---

## Conclusion

This deep dive into the Inferno codebase and architecture has revealed both the strengths of the current design and the spots where consistency can be improved. By formalizing the architecture rules into an automated linter and methodically refactoring the existing code, the team will achieve a more DRY, clean, and domain-aligned codebase.

These changes not only enforce best practices like separation of concerns and single source of truth, but they also set the stage for future development:

- New contributors (or AI copilots) will find a clear structure to follow.
- The risk of regressions or architectural drift will be much lower with lint checks in CI.
- The code will be easier to extend (e.g., adding a new domain model or tool will be straightforward when everything is in its place).

With the tasks outlined above, the next step is execution. Breaking down the work into the planned stages (scaffolding the linter, implementing rules, refactoring code by category, and adjusting tests) will allow gradual progress without destabilizing the main branch. As each rule goes from warning to error, the team can be confident that particular class of issues is resolved.

**In summary:** After this initiative, Inferno’s code quality and maintainability will reach a new level, and the architectural vision (enforced by InfernoLint) will guide all development moving forward. The result will be a robust framework that upholds the principles of clarity, correctness, and consistency throughout its lifecycle.
